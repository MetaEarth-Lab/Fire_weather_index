{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from netCDF4 import Dataset, date2num\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cf\n",
    "import warnings\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "from datetime import datetime, timedelta\n",
    "from collections import defaultdict\n",
    "from shapely import vectorized\n",
    "\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 각 기후 모델별 mean, std, max 값 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "GCMs_list = ['GFDL-ESM4', 'IPSL-CM6A-LR', 'MPI-ESM1-2-HR', 'MRI-ESM2-0', 'UKESM1-0-LL']\n",
    "data_types = [\"historical\", \"picontrol\"]\n",
    "\n",
    "shapefile_path = \"./shape_file_10m_cultural/ne_10m_admin_0_countries.shp\"\n",
    "gdf_borders = gpd.read_file(shapefile_path)\n",
    "korea = gdf_borders[gdf_borders['SOVEREIGNT'].isin(['South Korea', 'North Korea'])].geometry.unary_union\n",
    "\n",
    "lon = np.load(\"../data/ISIMIP_ko_lon_2km.npy\")  # (601,)\n",
    "lat = np.load(\"../data/ISIMIP_ko_lat_2km.npy\")  # (601,)\n",
    "\n",
    "lon_grid, lat_grid = np.meshgrid(lon, lat)\n",
    "mask = vectorized.contains(korea, lon_grid, lat_grid)\n",
    "\n",
    "for data_type_ in data_types:\n",
    "    for GCM in GCMs_list:\n",
    "        # 📌 데이터가 저장된 경로\n",
    "        data_dir = f\"../result/HR/{data_type_}/{GCM}/origin_fwi\"\n",
    "        result_path = f\"../result/{data_type_}/{GCM}\"\n",
    "        # 📌 날짜별 데이터를 저장할 딕셔너리\n",
    "        daily_data = defaultdict(list)\n",
    "\n",
    "        # 📌 모든 파일을 가져와 월/일별 그룹화\n",
    "        for file_name in sorted(os.listdir(data_dir)):\n",
    "            if file_name.endswith(\".npy\") and file_name.startswith(\"20\"):  # 2000~2014년 데이터만 필터링\n",
    "                mmdd = file_name[4:8]  # 'MMDD' 추출 (ex: 0101, 0215, ...)\n",
    "                if mmdd == \"0229\":\n",
    "                    continue\n",
    "                file_path = os.path.join(data_dir, file_name)\n",
    "\n",
    "                data = np.load(file_path)  # (601, 601) 형태\n",
    "\n",
    "                data = np.where(np.flipud(mask), data, np.nan)\n",
    "                daily_data[mmdd].append(data)\n",
    "\n",
    "        # 📌 결과를 저장할 배열 (365일 또는 366일)\n",
    "        num_days = len(daily_data)  # 365 또는 366\n",
    "        sample_shape = list(daily_data.values())[0][0].shape  # (601, 601)\n",
    "        daily_mean = np.zeros((num_days, *sample_shape), dtype=np.float32)\n",
    "        daily_std = np.zeros((num_days, *sample_shape), dtype=np.float32)\n",
    "        daily_max = np.zeros((num_days, *sample_shape), dtype=np.float32)\n",
    "\n",
    "        # 📌 각 월/일별 평균 & 표준편차 계산\n",
    "        for i, (mmdd, data_list) in enumerate(sorted(daily_data.items())):\n",
    "            data_stack = np.stack(data_list)  # (15, 601, 601)\n",
    "            daily_mean[i] = np.mean(data_stack, axis=0)  # 평균 계산\n",
    "            daily_std[i] = np.std(data_stack, axis=0)  # 표준편차 계산\n",
    "            daily_max[i] = np.max(data_stack, axis=0)  # max 계산\n",
    "            print(f\"✅ {mmdd} 완료: {len(data_list)}년 데이터 처리됨\")\n",
    "\n",
    "        # 📌 최종 결과 저장\n",
    "        np.save(os.path.join(result_path, \"daily_mean_ko.npy\"), daily_mean)\n",
    "        np.save(os.path.join(result_path, \"daily_std_ko.npy\"), daily_std)\n",
    "        np.save(os.path.join(result_path, \"daily_max_ko.npy\"), daily_max)\n",
    "\n",
    "print(\"🎯 모든 월/일별 mean, std, max 계산 완료 및 저장됨!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 기후 모델 취합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# GCM 리스트\n",
    "GCMs_list = ['GFDL-ESM4', 'IPSL-CM6A-LR', 'MPI-ESM1-2-HR', 'MRI-ESM2-0', 'UKESM1-0-LL']\n",
    "\n",
    "# 결과를 누적할 리스트\n",
    "data_list = []\n",
    "\n",
    "# 각 GCM별로 파일 로드 (파일 경로는 예시로 구성됨)\n",
    "for gcm in GCMs_list:\n",
    "    file_path = f\"/lustre/home/ebcho/workspace/pyfwi/SR_ISIMIP/result/historical/{gcm}/daily_max_ko.npy\"\n",
    "    try:\n",
    "        arr = np.load(file_path)  # (365, 601, 601)\n",
    "        data_list.append(arr)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ {gcm} 파일 로드 실패:\", e)\n",
    "\n",
    "# 평균 계산\n",
    "if data_list:\n",
    "    stacked = np.stack(data_list, axis=0)  # shape: (5, 365, 601, 601)\n",
    "    mean_result = np.mean(stacked, axis=0)  # shape: (365, 601, 601)\n",
    "else:\n",
    "    mean_result = None\n",
    "    print(\"📂 유효한 데이터 없음\")\n",
    "\n",
    "np.save(\"/lustre/home/ebcho/workspace/pyfwi/SR_ISIMIP/result/historical/all_gcm_fwi.npy\", mean_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. nc 파일로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 🔹 데이터 경로 설정\n",
    "fwi_path = \"/lustre/home/ebcho/workspace/pyfwi/SR_ISIMIP/result/historical/all_gcm_fwi.npy\"\n",
    "output_nc_path = \"/lustre/home/ebcho/workspace/pyfwi/SR_ISIMIP/result/historical/all_gcm_fwi.nc\"\n",
    "\n",
    "\n",
    "# 🔹 첫 번째 파일 로드하여 shape 확인\n",
    "all_fwi = np.load(fwi_path)\n",
    "lat_dim, lon_dim = all_fwi[0].shape[0], all_fwi[0].shape[1]\n",
    "\n",
    "\n",
    "# 🔹 위도, 경도 데이터 로드\n",
    "lat = np.load(\"./data/ISIMIP_ko_lat_2km.npy\")\n",
    "lon = np.load(\"./data/ISIMIP_ko_lon_2km.npy\")\n",
    "\n",
    "mean_std_times = [datetime(2000, 1, 1) + timedelta(days=i) for i in range(365)]\n",
    "day_of_year = np.arange(1, 366)  # 1~365일\n",
    "# print(len(mean_std_times), len(day_of_year))\n",
    "\n",
    "# 📌 NetCDF 파일 생성 (`xarray.Dataset`)\n",
    "ds = xr.Dataset(\n",
    "    {\n",
    "        \"FWI_all\": ([\"time_mean\", \"lat\", \"lon\"], all_fwi),  # FWI (2000~2014)\n",
    "        \"day_of_year\": ([\"time_mean\"], day_of_year),  # 추가된 day_of_year 변수\n",
    "    },\n",
    "    coords={\n",
    "        \"time_mean\": mean_std_times,  # 1년 365일 (2000년 기준)\n",
    "        \"lat\": lat,\n",
    "        \"lon\": lon,\n",
    "    }\n",
    ")\n",
    "\n",
    "# 📌 NetCDF 파일 저장\n",
    "ds.to_netcdf(output_nc_path)\n",
    "print(f\"✅ NetCDF 파일 저장 완료: {output_nc_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
